{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9806e93b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>author_display_name</th>\n",
       "      <th>text</th>\n",
       "      <th>published_at</th>\n",
       "      <th>like_count</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1WXfqPbbIZs</td>\n",
       "      <td>UgwRGq0gYoccep-QbEB4AaABAg</td>\n",
       "      <td>@Clarenentertainment</td>\n",
       "      <td>belum lagi ada QRIS TAB , ngak perlu scan ting...</td>\n",
       "      <td>2025-05-12T04:51:47Z</td>\n",
       "      <td>0</td>\n",
       "      <td>qris tab scan tinggal tab project qris cross b...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1WXfqPbbIZs</td>\n",
       "      <td>UgyY_wpOV8wYMNQSDSB4AaABAg</td>\n",
       "      <td>@asrilmohammad3922</td>\n",
       "      <td>Bro negara Thailand elu salah bidik, yang dika...</td>\n",
       "      <td>2025-05-12T04:16:30Z</td>\n",
       "      <td>1</td>\n",
       "      <td>bro negara thailand lu salah bidik dikau myanm...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1WXfqPbbIZs</td>\n",
       "      <td>UgxKqKc8vcLbTTW7BLd4AaABAg</td>\n",
       "      <td>@gna3276</td>\n",
       "      <td>kalau sampe Qris ada campur tangan politik apa...</td>\n",
       "      <td>2025-05-12T03:31:02Z</td>\n",
       "      <td>0</td>\n",
       "      <td>qris campur tangan politik pengusaha soksok ca...</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1WXfqPbbIZs</td>\n",
       "      <td>UgwmPDaHsHq3-Pij32N4AaABAg</td>\n",
       "      <td>@AdhiChandra-nw7rm</td>\n",
       "      <td>Panjang umur lu yg bikin qris. Sumpah mempermu...</td>\n",
       "      <td>2025-05-12T03:22:56Z</td>\n",
       "      <td>0</td>\n",
       "      <td>umur lu bikin qris sumpah mempermudah bgtttttt...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1WXfqPbbIZs</td>\n",
       "      <td>Ugw9TB3panTmNVEN4Mt4AaABAg</td>\n",
       "      <td>@akonaja6876</td>\n",
       "      <td>ini yg betul sebutannya  QR (kiu-ar) code, BUK...</td>\n",
       "      <td>2025-05-12T03:20:19Z</td>\n",
       "      <td>0</td>\n",
       "      <td>sebutannya qr kiuar code barcode banget barcod...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>1WXfqPbbIZs</td>\n",
       "      <td>Ugx6EhkuFpWvIgU8rDN4AaABAg</td>\n",
       "      <td>@lisahoshiko9</td>\n",
       "      <td>Berita ini banyak di bahas nih, Indonesia puny...</td>\n",
       "      <td>2025-05-05T11:29:10Z</td>\n",
       "      <td>59</td>\n",
       "      <td>berita bahas nih indonesia peraturan negara ca...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>1WXfqPbbIZs</td>\n",
       "      <td>UgwI42udmRLBzfiqEAl4AaABAg</td>\n",
       "      <td>@kusnaningsih8052</td>\n",
       "      <td>Gw beli bakso ma ketoprak doank byr nya pake q...</td>\n",
       "      <td>2025-05-05T11:27:49Z</td>\n",
       "      <td>3</td>\n",
       "      <td>gue beli bakso ketoprak doang byr nya pakai qr...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>1WXfqPbbIZs</td>\n",
       "      <td>UgzsocGsk4IOrcHoRF14AaABAg</td>\n",
       "      <td>@federicoolz</td>\n",
       "      <td>Sistem SWIFT selama ini benar-benar membahayak...</td>\n",
       "      <td>2025-05-05T11:27:07Z</td>\n",
       "      <td>2</td>\n",
       "      <td>sistem swift benarbenar membahayakan keamanan ...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>1WXfqPbbIZs</td>\n",
       "      <td>Ugw8J4Le6DOvFmMjIHd4AaABAg</td>\n",
       "      <td>@aldikoret5011</td>\n",
       "      <td>Judol transaksi nya pakai qris makannya gede p...</td>\n",
       "      <td>2025-05-05T11:25:13Z</td>\n",
       "      <td>0</td>\n",
       "      <td>judol transaksi nya pakai qris makannya gede p...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>1WXfqPbbIZs</td>\n",
       "      <td>Ugxjr4nQmhj25rqsc0l4AaABAg</td>\n",
       "      <td>@verdy8623</td>\n",
       "      <td>Makasi informasi nya bangüôèüèª\\nSmangat truss bua...</td>\n",
       "      <td>2025-05-05T11:21:49Z</td>\n",
       "      <td>2</td>\n",
       "      <td>terima kasih informasi nya bang semangat truss...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1801 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id                  comment_id   author_display_name  \\\n",
       "0     1WXfqPbbIZs  UgwRGq0gYoccep-QbEB4AaABAg  @Clarenentertainment   \n",
       "1     1WXfqPbbIZs  UgyY_wpOV8wYMNQSDSB4AaABAg    @asrilmohammad3922   \n",
       "2     1WXfqPbbIZs  UgxKqKc8vcLbTTW7BLd4AaABAg              @gna3276   \n",
       "3     1WXfqPbbIZs  UgwmPDaHsHq3-Pij32N4AaABAg    @AdhiChandra-nw7rm   \n",
       "4     1WXfqPbbIZs  Ugw9TB3panTmNVEN4Mt4AaABAg          @akonaja6876   \n",
       "...           ...                         ...                   ...   \n",
       "1796  1WXfqPbbIZs  Ugx6EhkuFpWvIgU8rDN4AaABAg         @lisahoshiko9   \n",
       "1797  1WXfqPbbIZs  UgwI42udmRLBzfiqEAl4AaABAg     @kusnaningsih8052   \n",
       "1798  1WXfqPbbIZs  UgzsocGsk4IOrcHoRF14AaABAg          @federicoolz   \n",
       "1799  1WXfqPbbIZs  Ugw8J4Le6DOvFmMjIHd4AaABAg        @aldikoret5011   \n",
       "1800  1WXfqPbbIZs  Ugxjr4nQmhj25rqsc0l4AaABAg            @verdy8623   \n",
       "\n",
       "                                                   text          published_at  \\\n",
       "0     belum lagi ada QRIS TAB , ngak perlu scan ting...  2025-05-12T04:51:47Z   \n",
       "1     Bro negara Thailand elu salah bidik, yang dika...  2025-05-12T04:16:30Z   \n",
       "2     kalau sampe Qris ada campur tangan politik apa...  2025-05-12T03:31:02Z   \n",
       "3     Panjang umur lu yg bikin qris. Sumpah mempermu...  2025-05-12T03:22:56Z   \n",
       "4     ini yg betul sebutannya  QR (kiu-ar) code, BUK...  2025-05-12T03:20:19Z   \n",
       "...                                                 ...                   ...   \n",
       "1796  Berita ini banyak di bahas nih, Indonesia puny...  2025-05-05T11:29:10Z   \n",
       "1797  Gw beli bakso ma ketoprak doank byr nya pake q...  2025-05-05T11:27:49Z   \n",
       "1798  Sistem SWIFT selama ini benar-benar membahayak...  2025-05-05T11:27:07Z   \n",
       "1799  Judol transaksi nya pakai qris makannya gede p...  2025-05-05T11:25:13Z   \n",
       "1800  Makasi informasi nya bangüôèüèª\\nSmangat truss bua...  2025-05-05T11:21:49Z   \n",
       "\n",
       "      like_count                                         clean_text  \\\n",
       "0              0  qris tab scan tinggal tab project qris cross b...   \n",
       "1              1  bro negara thailand lu salah bidik dikau myanm...   \n",
       "2              0  qris campur tangan politik pengusaha soksok ca...   \n",
       "3              0  umur lu bikin qris sumpah mempermudah bgtttttt...   \n",
       "4              0  sebutannya qr kiuar code barcode banget barcod...   \n",
       "...          ...                                                ...   \n",
       "1796          59  berita bahas nih indonesia peraturan negara ca...   \n",
       "1797           3  gue beli bakso ketoprak doang byr nya pakai qr...   \n",
       "1798           2  sistem swift benarbenar membahayakan keamanan ...   \n",
       "1799           0  judol transaksi nya pakai qris makannya gede p...   \n",
       "1800           2  terima kasih informasi nya bang semangat truss...   \n",
       "\n",
       "      word_count  \n",
       "0              9  \n",
       "1             13  \n",
       "2             44  \n",
       "3              9  \n",
       "4             14  \n",
       "...          ...  \n",
       "1796           7  \n",
       "1797          11  \n",
       "1798          20  \n",
       "1799           9  \n",
       "1800          10  \n",
       "\n",
       "[1801 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/youtube_comments_id_cleaned.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c01f9ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Panjang umur lu yang bikin qris.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from indoNLP.preprocessing import replace_slang, replace_word_elongation\n",
    "\n",
    "replace_slang(\"Panjang umur lu yg bikin qris.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0dadbe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bagus banget'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_word_elongation(\"baguss bangettttt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91fdd425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4384d1a89864d368e0d371ac481a8bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48515ccdb938466396444077f235f21a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/793k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "926fb3a78a7d45b9b5e389efd2b75881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d069f03ec6045d0a053eafede3d8003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/657 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e201c12a91fe41d79b625da30f329ca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623622c5418249ed982f48be56da0b31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dari 387 komentar yang dianalisis, 68. 2% penonton memberikan respon positif, 21.4% negatif, dan 10.3% netral. Banyak penonton menyukai video karena hal-hal seperti 'visual' dan \"narasi\".\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"cahya/t5-base-indonesian-summarization-cased\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"cahya/t5-base-indonesian-summarization-cased\")\n",
    "\n",
    "# \n",
    "ARTICLE_TO_SUMMARIZE = 'Dari 387 komentar yang dianalisis, 68.2% penonton memberikan respon positif, 21.4% negatif, dan 10.3% netral. Banyak penonton menyukai video karena hal-hal seperti \"visual\" dan \"narasi\". Namun, beberapa penonton menyampaikan kritik terkait \"durasi\" dan \"penjelasan\". Beberapa kata yang sering muncul dalam komentar antara lain: keren, jelas, panjang, saran, detail.'\n",
    "\n",
    "# generate summary\n",
    "input_ids = tokenizer.encode(ARTICLE_TO_SUMMARIZE, return_tensors='pt')\n",
    "summary_ids = model.generate(input_ids,\n",
    "            min_length=20,\n",
    "            max_length=80,\n",
    "            num_beams=10,\n",
    "            repetition_penalty=2.5,\n",
    "            length_penalty=1.0,\n",
    "            early_stopping=True,\n",
    "            no_repeat_ngram_size=2,\n",
    "            use_cache=True,\n",
    "            do_sample = True,\n",
    "            temperature = 0.8,\n",
    "            top_k = 50,\n",
    "            top_p = 0.95)\n",
    "\n",
    "summary_text = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "print(summary_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00b5b077",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a5213fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>author_display_name</th>\n",
       "      <th>text</th>\n",
       "      <th>published_at</th>\n",
       "      <th>like_count</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1WXfqPbbIZs</td>\n",
       "      <td>UgwRGq0gYoccep-QbEB4AaABAg</td>\n",
       "      <td>@Clarenentertainment</td>\n",
       "      <td>belum lagi ada QRIS TAB , ngak perlu scan ting...</td>\n",
       "      <td>2025-05-12T04:51:47Z</td>\n",
       "      <td>0</td>\n",
       "      <td>qris tab ngak scan tinggal tab project qris cr...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1WXfqPbbIZs</td>\n",
       "      <td>UgyY_wpOV8wYMNQSDSB4AaABAg</td>\n",
       "      <td>@asrilmohammad3922</td>\n",
       "      <td>Bro negara Thailand elu salah bidik, yang dika...</td>\n",
       "      <td>2025-05-12T04:16:30Z</td>\n",
       "      <td>1</td>\n",
       "      <td>bro negara thailand elu salah bidik dikau myan...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1WXfqPbbIZs</td>\n",
       "      <td>UgxKqKc8vcLbTTW7BLd4AaABAg</td>\n",
       "      <td>@gna3276</td>\n",
       "      <td>kalau sampe Qris ada campur tangan politik apa...</td>\n",
       "      <td>2025-05-12T03:31:02Z</td>\n",
       "      <td>0</td>\n",
       "      <td>sampe qris campur tangan politik pengusaha sok...</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1WXfqPbbIZs</td>\n",
       "      <td>UgwmPDaHsHq3-Pij32N4AaABAg</td>\n",
       "      <td>@AdhiChandra-nw7rm</td>\n",
       "      <td>Panjang umur lu yg bikin qris. Sumpah mempermu...</td>\n",
       "      <td>2025-05-12T03:22:56Z</td>\n",
       "      <td>0</td>\n",
       "      <td>umur lu yg bikin qris sumpah mempermudah bgttt...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1WXfqPbbIZs</td>\n",
       "      <td>Ugw9TB3panTmNVEN4Mt4AaABAg</td>\n",
       "      <td>@akonaja6876</td>\n",
       "      <td>ini yg betul sebutannya  QR (kiu-ar) code, BUK...</td>\n",
       "      <td>2025-05-12T03:20:19Z</td>\n",
       "      <td>0</td>\n",
       "      <td>yg sebutannya qr kiuar code barcode banget bar...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                  comment_id   author_display_name  \\\n",
       "0  1WXfqPbbIZs  UgwRGq0gYoccep-QbEB4AaABAg  @Clarenentertainment   \n",
       "1  1WXfqPbbIZs  UgyY_wpOV8wYMNQSDSB4AaABAg    @asrilmohammad3922   \n",
       "2  1WXfqPbbIZs  UgxKqKc8vcLbTTW7BLd4AaABAg              @gna3276   \n",
       "3  1WXfqPbbIZs  UgwmPDaHsHq3-Pij32N4AaABAg    @AdhiChandra-nw7rm   \n",
       "4  1WXfqPbbIZs  Ugw9TB3panTmNVEN4Mt4AaABAg          @akonaja6876   \n",
       "\n",
       "                                                text          published_at  \\\n",
       "0  belum lagi ada QRIS TAB , ngak perlu scan ting...  2025-05-12T04:51:47Z   \n",
       "1  Bro negara Thailand elu salah bidik, yang dika...  2025-05-12T04:16:30Z   \n",
       "2  kalau sampe Qris ada campur tangan politik apa...  2025-05-12T03:31:02Z   \n",
       "3  Panjang umur lu yg bikin qris. Sumpah mempermu...  2025-05-12T03:22:56Z   \n",
       "4  ini yg betul sebutannya  QR (kiu-ar) code, BUK...  2025-05-12T03:20:19Z   \n",
       "\n",
       "   like_count                                         clean_text  word_count  \n",
       "0           0  qris tab ngak scan tinggal tab project qris cr...          10  \n",
       "1           1  bro negara thailand elu salah bidik dikau myan...          13  \n",
       "2           0  sampe qris campur tangan politik pengusaha sok...          47  \n",
       "3           0  umur lu yg bikin qris sumpah mempermudah bgttt...          10  \n",
       "4           0  yg sebutannya qr kiuar code barcode banget bar...          16  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/youtube_comments_id_cleaned.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cdc2572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>author_display_name</th>\n",
       "      <th>text</th>\n",
       "      <th>published_at</th>\n",
       "      <th>like_count</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>1WXfqPbbIZs</td>\n",
       "      <td>UgwJKj4IywoEcXjwE4Z4AaABAg</td>\n",
       "      <td>@ErieWidjoyoHartanto</td>\n",
       "      <td>Padal keris itu benda tradisi Jawa Indonesia h...</td>\n",
       "      <td>2025-05-05T11:33:46Z</td>\n",
       "      <td>1</td>\n",
       "      <td>padal keris benda tradisi jawa indonesia hrusn...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>1WXfqPbbIZs</td>\n",
       "      <td>UgzgOgLZObVAraIpqKt4AaABAg</td>\n",
       "      <td>@usercrythu</td>\n",
       "      <td>Enak ke warteg ga perlu bawa duit cash dan war...</td>\n",
       "      <td>2025-05-05T11:33:41Z</td>\n",
       "      <td>6</td>\n",
       "      <td>enak warteg ga bawa duit cash warteg ga repot ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>1WXfqPbbIZs</td>\n",
       "      <td>UgyiDG5fHMvwLFsOseR4AaABAg</td>\n",
       "      <td>@obamaissus1586</td>\n",
       "      <td>BANG NAPA BANAK BOT JUDOL SIH</td>\n",
       "      <td>2025-05-05T11:32:05Z</td>\n",
       "      <td>0</td>\n",
       "      <td>bang napa banak bot judol sih</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>1WXfqPbbIZs</td>\n",
       "      <td>UgyesdpQMtzR5nGAr2d4AaABAg</td>\n",
       "      <td>@minitaur</td>\n",
       "      <td>Pejabat Indonesia klo mau serius kerja mah pas...</td>\n",
       "      <td>2025-05-05T11:29:49Z</td>\n",
       "      <td>14</td>\n",
       "      <td>pejabat indonesia klo serius kerja mah sukses ...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>1WXfqPbbIZs</td>\n",
       "      <td>Ugx6EhkuFpWvIgU8rDN4AaABAg</td>\n",
       "      <td>@lisahoshiko9</td>\n",
       "      <td>Berita ini banyak di bahas nih, Indonesia puny...</td>\n",
       "      <td>2025-05-05T11:29:10Z</td>\n",
       "      <td>59</td>\n",
       "      <td>berita bahas nih indonesia peraturan jgn negar...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>1WXfqPbbIZs</td>\n",
       "      <td>UgyiAy2VxYZVI0csruF4AaABAg</td>\n",
       "      <td>@hrManagement-j7l</td>\n",
       "      <td>Kalau nggak nurut USA, seperti biasa mereka ak...</td>\n",
       "      <td>2025-05-05T11:27:56Z</td>\n",
       "      <td>115</td>\n",
       "      <td>nggak nurut usa berusaha mengganti penguasanya...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>1WXfqPbbIZs</td>\n",
       "      <td>UgwI42udmRLBzfiqEAl4AaABAg</td>\n",
       "      <td>@kusnaningsih8052</td>\n",
       "      <td>Gw beli bakso ma ketoprak doank byr nya pake q...</td>\n",
       "      <td>2025-05-05T11:27:49Z</td>\n",
       "      <td>3</td>\n",
       "      <td>gw beli bakso ketoprak doank byr nya pake qris...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>1WXfqPbbIZs</td>\n",
       "      <td>UgzsocGsk4IOrcHoRF14AaABAg</td>\n",
       "      <td>@federicoolz</td>\n",
       "      <td>Sistem SWIFT selama ini benar-benar membahayak...</td>\n",
       "      <td>2025-05-05T11:27:07Z</td>\n",
       "      <td>2</td>\n",
       "      <td>sistem swift benarbenar membahayakan keamanan ...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>1WXfqPbbIZs</td>\n",
       "      <td>Ugw8J4Le6DOvFmMjIHd4AaABAg</td>\n",
       "      <td>@aldikoret5011</td>\n",
       "      <td>Judol transaksi nya pakai qris makannya gede p...</td>\n",
       "      <td>2025-05-05T11:25:13Z</td>\n",
       "      <td>0</td>\n",
       "      <td>judol transaksi nya pakai qris makannya gede p...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>1WXfqPbbIZs</td>\n",
       "      <td>Ugxjr4nQmhj25rqsc0l4AaABAg</td>\n",
       "      <td>@verdy8623</td>\n",
       "      <td>Makasi informasi nya bangüôèüèª\\nSmangat truss bua...</td>\n",
       "      <td>2025-05-05T11:21:49Z</td>\n",
       "      <td>2</td>\n",
       "      <td>makasi informasi nya bang smangat truss nge ed...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id                  comment_id   author_display_name  \\\n",
       "1593  1WXfqPbbIZs  UgwJKj4IywoEcXjwE4Z4AaABAg  @ErieWidjoyoHartanto   \n",
       "1594  1WXfqPbbIZs  UgzgOgLZObVAraIpqKt4AaABAg           @usercrythu   \n",
       "1595  1WXfqPbbIZs  UgyiDG5fHMvwLFsOseR4AaABAg       @obamaissus1586   \n",
       "1596  1WXfqPbbIZs  UgyesdpQMtzR5nGAr2d4AaABAg             @minitaur   \n",
       "1597  1WXfqPbbIZs  Ugx6EhkuFpWvIgU8rDN4AaABAg         @lisahoshiko9   \n",
       "1598  1WXfqPbbIZs  UgyiAy2VxYZVI0csruF4AaABAg     @hrManagement-j7l   \n",
       "1599  1WXfqPbbIZs  UgwI42udmRLBzfiqEAl4AaABAg     @kusnaningsih8052   \n",
       "1600  1WXfqPbbIZs  UgzsocGsk4IOrcHoRF14AaABAg          @federicoolz   \n",
       "1601  1WXfqPbbIZs  Ugw8J4Le6DOvFmMjIHd4AaABAg        @aldikoret5011   \n",
       "1602  1WXfqPbbIZs  Ugxjr4nQmhj25rqsc0l4AaABAg            @verdy8623   \n",
       "\n",
       "                                                   text          published_at  \\\n",
       "1593  Padal keris itu benda tradisi Jawa Indonesia h...  2025-05-05T11:33:46Z   \n",
       "1594  Enak ke warteg ga perlu bawa duit cash dan war...  2025-05-05T11:33:41Z   \n",
       "1595                      BANG NAPA BANAK BOT JUDOL SIH  2025-05-05T11:32:05Z   \n",
       "1596  Pejabat Indonesia klo mau serius kerja mah pas...  2025-05-05T11:29:49Z   \n",
       "1597  Berita ini banyak di bahas nih, Indonesia puny...  2025-05-05T11:29:10Z   \n",
       "1598  Kalau nggak nurut USA, seperti biasa mereka ak...  2025-05-05T11:27:56Z   \n",
       "1599  Gw beli bakso ma ketoprak doank byr nya pake q...  2025-05-05T11:27:49Z   \n",
       "1600  Sistem SWIFT selama ini benar-benar membahayak...  2025-05-05T11:27:07Z   \n",
       "1601  Judol transaksi nya pakai qris makannya gede p...  2025-05-05T11:25:13Z   \n",
       "1602  Makasi informasi nya bangüôèüèª\\nSmangat truss bua...  2025-05-05T11:21:49Z   \n",
       "\n",
       "      like_count                                         clean_text  \\\n",
       "1593           1  padal keris benda tradisi jawa indonesia hrusn...   \n",
       "1594           6  enak warteg ga bawa duit cash warteg ga repot ...   \n",
       "1595           0                      bang napa banak bot judol sih   \n",
       "1596          14  pejabat indonesia klo serius kerja mah sukses ...   \n",
       "1597          59  berita bahas nih indonesia peraturan jgn negar...   \n",
       "1598         115  nggak nurut usa berusaha mengganti penguasanya...   \n",
       "1599           3  gw beli bakso ketoprak doank byr nya pake qris...   \n",
       "1600           2  sistem swift benarbenar membahayakan keamanan ...   \n",
       "1601           0  judol transaksi nya pakai qris makannya gede p...   \n",
       "1602           2  makasi informasi nya bang smangat truss nge ed...   \n",
       "\n",
       "      word_count  \n",
       "1593          33  \n",
       "1594          12  \n",
       "1595           6  \n",
       "1596          21  \n",
       "1597           8  \n",
       "1598           7  \n",
       "1599          11  \n",
       "1600          20  \n",
       "1601           9  \n",
       "1602           9  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0500b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1603, 8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74984139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert csv to excel\n",
    "df.to_excel('../data/youtube_comments_id_with_sentiment.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ab3215c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memang terbaik ini hoki777 gak bohong gue mantab bang\n"
     ]
    }
   ],
   "source": [
    "from unidecode import unidecode\n",
    "text = \"Memang terbaik ini ùíâùíêùíåùíä777 gak bohong gue mantab bang\"\n",
    "\n",
    "print(unidecode(text).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "088f4414",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = df['clean_text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6349351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe49c3df3184415939a307a3a9dfc5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20a95a4cf69b4c259d731b2b6bacd93f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c19aafcea3e458189e9a80d14880573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.26k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81fabb8fc7cf4bde911bcc89f4f2c445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac7ff58ecc8546f6876764fda0c1072f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/16.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eacaace3606f4c829741967cb7119f8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/23.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b559c024b3b04e14ad49cdaff0de1e35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/286 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Load zero-shot classifier pipeline dengan mDeBERTa\n",
    "classifier = pipeline(\n",
    "    task=\"zero-shot-classification\",\n",
    "    model=\"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n",
    ")\n",
    "\n",
    "# Label yang ingin diuji\n",
    "labels = [\"positive\", \"neutral\", \"negative\"]\n",
    "\n",
    "# Menyimpan hasil\n",
    "sentiment_labels = []\n",
    "sentiment_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db3f49ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sentiment analysis in batches of 32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "69it [32:07, 27.93s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRunning sentiment analysis in batches of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch_comments \u001b[38;5;129;01min\u001b[39;00m tqdm(batch(comments, batch_size)):\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     results = \u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_comments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_labels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhypothesis_template\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mThis text is \u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[33;43m.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m     \u001b[38;5;66;03m# Untuk hasil batch, kita proses tiap elemen\u001b[39;00m\n\u001b[32m     23\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/pipelines/zero_shot_classification.py:206\u001b[39m, in \u001b[36mZeroShotClassificationPipeline.__call__\u001b[39m\u001b[34m(self, sequences, *args, **kwargs)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnable to understand extra arguments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/pipelines/base.py:1360\u001b[39m, in \u001b[36mPipeline.__call__\u001b[39m\u001b[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[39m\n\u001b[32m   1356\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n\u001b[32m   1357\u001b[39m     final_iterator = \u001b[38;5;28mself\u001b[39m.get_iterator(\n\u001b[32m   1358\u001b[39m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[32m   1359\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1360\u001b[39m     outputs = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfinal_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1361\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[32m   1362\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:124\u001b[39m, in \u001b[36mPipelineIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loader_batch_item()\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m item = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m processed = \u001b[38;5;28mself\u001b[39m.infer(item, **\u001b[38;5;28mself\u001b[39m.params)\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:269\u001b[39m, in \u001b[36mPipelinePackIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    266\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m accumulator\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last:\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m     processed = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    270\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    271\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed, torch.Tensor):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/pipelines/base.py:1286\u001b[39m, in \u001b[36mPipeline.forward\u001b[39m\u001b[34m(self, model_inputs, **forward_params)\u001b[39m\n\u001b[32m   1284\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[32m   1285\u001b[39m         model_inputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_inputs, device=\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m-> \u001b[39m\u001b[32m1286\u001b[39m         model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1287\u001b[39m         model_outputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_outputs, device=torch.device(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   1288\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/pipelines/zero_shot_classification.py:229\u001b[39m, in \u001b[36mZeroShotClassificationPipeline._forward\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inspect.signature(model_forward).parameters.keys():\n\u001b[32m    228\u001b[39m     model_inputs[\u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    231\u001b[39m model_outputs = {\n\u001b[32m    232\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcandidate_label\u001b[39m\u001b[33m\"\u001b[39m: candidate_label,\n\u001b[32m    233\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msequence\u001b[39m\u001b[33m\"\u001b[39m: sequence,\n\u001b[32m    234\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mis_last\u001b[39m\u001b[33m\"\u001b[39m: inputs[\u001b[33m\"\u001b[39m\u001b[33mis_last\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    235\u001b[39m     **outputs,\n\u001b[32m    236\u001b[39m }\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model_outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:1179\u001b[39m, in \u001b[36mDebertaV2ForSequenceClassification.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1171\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1172\u001b[39m \u001b[33;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[32m   1173\u001b[39m \u001b[33;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[32m   1174\u001b[39m \u001b[33;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[32m   1175\u001b[39m \u001b[33;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[32m   1176\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1177\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m-> \u001b[39m\u001b[32m1179\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdeberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1181\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1188\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1190\u001b[39m encoder_layer = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1191\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.pooler(encoder_layer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:874\u001b[39m, in \u001b[36mDebertaV2Model.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    864\u001b[39m     token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n\u001b[32m    866\u001b[39m embedding_output = \u001b[38;5;28mself\u001b[39m.embeddings(\n\u001b[32m    867\u001b[39m     input_ids=input_ids,\n\u001b[32m    868\u001b[39m     token_type_ids=token_type_ids,\n\u001b[32m   (...)\u001b[39m\u001b[32m    871\u001b[39m     inputs_embeds=inputs_embeds,\n\u001b[32m    872\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m874\u001b[39m encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m encoded_layers = encoder_outputs[\u001b[32m1\u001b[39m]\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.z_steps > \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:674\u001b[39m, in \u001b[36mDebertaV2Encoder.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, output_hidden_states, output_attentions, query_states, relative_pos, return_dict)\u001b[39m\n\u001b[32m    664\u001b[39m     output_states, attn_weights = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m    665\u001b[39m         layer_module.\u001b[34m__call__\u001b[39m,\n\u001b[32m    666\u001b[39m         next_kv,\n\u001b[32m   (...)\u001b[39m\u001b[32m    671\u001b[39m         output_attentions,\n\u001b[32m    672\u001b[39m     )\n\u001b[32m    673\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m674\u001b[39m     output_states, attn_weights = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnext_kv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    680\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[32m    684\u001b[39m     all_attentions = all_attentions + (attn_weights,)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:442\u001b[39m, in \u001b[36mDebertaV2Layer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, query_states, relative_pos, rel_embeddings, output_attentions)\u001b[39m\n\u001b[32m    433\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    434\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    435\u001b[39m     hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    440\u001b[39m     output_attentions: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    441\u001b[39m ) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m     attention_output, att_matrix = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    445\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    446\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    448\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    449\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    450\u001b[39m     intermediate_output = \u001b[38;5;28mself\u001b[39m.intermediate(attention_output)\n\u001b[32m    451\u001b[39m     layer_output = \u001b[38;5;28mself\u001b[39m.output(intermediate_output, attention_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:375\u001b[39m, in \u001b[36mDebertaV2Attention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    367\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    368\u001b[39m     hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    373\u001b[39m     rel_embeddings=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    374\u001b[39m ) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m     self_output, att_matrix = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    383\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m query_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    384\u001b[39m         query_states = hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:240\u001b[39m, in \u001b[36mDisentangledSelfAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m query_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    239\u001b[39m     query_states = hidden_states\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m query_layer = \u001b[38;5;28mself\u001b[39m.transpose_for_scores(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mquery_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m.num_attention_heads)\n\u001b[32m    241\u001b[39m key_layer = \u001b[38;5;28mself\u001b[39m.transpose_for_scores(\u001b[38;5;28mself\u001b[39m.key_proj(hidden_states), \u001b[38;5;28mself\u001b[39m.num_attention_heads)\n\u001b[32m    242\u001b[39m value_layer = \u001b[38;5;28mself\u001b[39m.transpose_for_scores(\u001b[38;5;28mself\u001b[39m.value_proj(hidden_states), \u001b[38;5;28mself\u001b[39m.num_attention_heads)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Inisialisasi hasil\n",
    "all_results = []\n",
    "\n",
    "# Parameter batching\n",
    "batch_size = 32  # ubah sesuai kebutuhan & kapasitas hardware\n",
    "\n",
    "# Fungsi untuk batching\n",
    "def batch(iterable, n=1):\n",
    "    length = len(iterable)\n",
    "    for i in range(0, length, n):\n",
    "        yield iterable[i:min(i + n, length)]\n",
    "\n",
    "print(f\"Running sentiment analysis in batches of {batch_size}...\")\n",
    "\n",
    "for batch_comments in tqdm(batch(comments, batch_size)):\n",
    "    results = classifier(\n",
    "        batch_comments,\n",
    "        candidate_labels=labels,\n",
    "        hypothesis_template=\"This text is {}.\"\n",
    "    )\n",
    "\n",
    "    # Untuk hasil batch, kita proses tiap elemen\n",
    "    for result in results:\n",
    "        all_results.append({\n",
    "            \"comment\": result['sequence'],\n",
    "            \"sentiment\": result['labels'][0],\n",
    "            \"confidence\": result['scores'][0]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab99205",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
